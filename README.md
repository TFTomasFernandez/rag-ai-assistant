ğŸ“š RAG Challenge â€” AI Assistant with Cohere
ğŸ§  Overview

This project implements a Retrieval-Augmented Generation (RAG) assistant using Cohere's cloud models for embeddings and language generation, combined with a local vector database (ChromaDB) for efficient semantic search over documents.

The assistant reads and understands PDF documents and allows users to ask natural language questions through a web interface, returning precise answers based strictly on the document content.

Everything runs inside Docker for portability and simple deployment.

-------------------------------------------------------------------------------------------

ğŸš€ Features

âœ… Multilingual support (English, Spanish, Portuguese)

âœ… Cohere-powered embeddings (cloud, lightweight)

âœ… Command-R language model via Cohere

âœ… Vector search with ChromaDB

âœ… Context-based answering (no hallucinations)

âœ… Language enforcement (answers follow user language)

âœ… Emoji summarization

âœ… Single-sentence answers

âœ… Dockerized system (no local Python install needed)

âœ… Simple web interface

âœ… Fully portable

------------------------------------------------------------------------------------------

ğŸ— Architecture

User (Browser UI)
        |
        v
FastAPI (API Layer)
        |
        v
ChromaDB (Vector Storage) â† Cohere Embeddings
        |
        v
Cohere LLM (Command-R)

-----------------------------------------------------------------------------------------

ğŸ“‚ Project Structure
.
â”œâ”€â”€ app.py                 # FastAPI backend
â”œâ”€â”€ query.py               # RAG logic + Cohere integration
â”œâ”€â”€ ingest.py              # Document processing + embedding
â”œâ”€â”€ config.py              # Paths and constants
â”œâ”€â”€ docker-compose.yml     # Docker orchestration
â”œâ”€â”€ Dockerfile             # Container definition
â”œâ”€â”€ requirements.txt       # Python dependencies
â”œâ”€â”€ ui.html                # Web interface
â”œâ”€â”€ README.md              # This file
â”‚
â”œâ”€â”€ data/                  # PDF documents folder
â”‚   â””â”€â”€ stories.pdf
â”‚
â””â”€â”€ vectordb/              # ChromaDB persistent database

------------------------------------------------------------------------------------------

âœ… Requirements (User)

Only one requirement:

ğŸ³ Docker Desktop installed

Download here:
https://www.docker.com/products/docker-desktop/

Ensure WSL2 is enabled and restart after installation if asked.

--------------------------------------------------------------------------------------------

âš™ Installation & Execution

* Step 1 â€” Clone or copy the project folder

This includes all files and the vectordb directory.

Create a file named ".env" in the folder main:

COHERE_API_KEY=YOUR_API_KEY_HERE


* Step 2 â€” Run the system

From inside the project folder:

docker compose up --build

Wait for:

Uvicorn running on http://0.0.0.0:8000

* Step 3 â€” Open the assistant

Open your browser:

ğŸ‘‰ http://localhost:8000

--------------------------------------------------------------------------------------------

ğŸ§ª Usage

Enter your name

Ask a question about the documents

Receive a contextual answer

Examples:

âœ… English:

What is the name of the magical flower?

âœ… Spanish:

Â¿CÃ³mo se llama la flor mÃ¡gica?

âœ… Portuguese:

Como se chama a flor mÃ¡gica?

------------------------------------------------------------------------------------------

ğŸ›‘ Stop the System

To shut everything down:

Press:

CTRL + C

------------------------------------------------------------------------------------------

ğŸ§¼ Reset Vector Database (Optional)

To re-index documents:

Delete folder:

vectordb/


Then run:

docker compose up --build

------------------------------------------------------------------------------------------

ğŸ’¡ Technical Stack

FastAPI

Cohere (embeddings + LLM)

ChromaDB

LangChain

Docker

Python 3.10

------------------------------------------------------------------------------------------

ğŸ“Œ Author

TomÃ¡s FernÃ¡ndez
AI Engineer & Data Scientist

Specialized in:

AI Agents

RAG systems

Cloud ML

NLP

MLOps
